{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array(Image.open(\"../resources/dog.jpeg\").convert('L'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19770384.              +0.j        ,\n",
       "          788374.43465155-1184768.21422914j,\n",
       "         -247797.26828835 +700144.43737151j, ...,\n",
       "         -341156.79129608 +833917.75854973j,\n",
       "         -247797.26828835 -700144.43737151j,\n",
       "          788374.43465155+1184768.21422914j],\n",
       "       [ 1021914.81553875 -535678.81516572j,\n",
       "         -106013.48291918+1291984.43331787j,\n",
       "          312357.18971136 -357967.95331175j, ...,\n",
       "           94875.52718759 -691581.59465561j,\n",
       "          231193.6689445  +556057.84867697j,\n",
       "        -1054640.05758519 +569737.23711162j],\n",
       "       [ -746130.83297157 -266878.13827965j,\n",
       "         -196412.41213424 +534397.95836987j,\n",
       "           87515.44773742 -346901.9140205j , ...,\n",
       "           71700.69789589  +80922.05025297j,\n",
       "          -33924.01450934 -929607.20436937j,\n",
       "           31559.81479789 +423509.04880684j],\n",
       "       ...,\n",
       "       [ -186573.474518   +418734.64761095j,\n",
       "          120496.73123925 +610930.32937845j,\n",
       "          264097.54402355 -549045.10505395j, ...,\n",
       "         -238859.2354294  +147466.42322418j,\n",
       "         -466485.87127828 -199059.03770011j,\n",
       "          363901.17548277 +139622.57484622j],\n",
       "       [ -746130.83297157 +266878.13827965j,\n",
       "           31559.81479789 -423509.04880684j,\n",
       "          -33924.01450934 +929607.20436937j, ...,\n",
       "         -131863.56129784 -498345.61188647j,\n",
       "           87515.44773742 +346901.9140205j ,\n",
       "         -196412.41213424 -534397.95836987j],\n",
       "       [ 1021914.81553875 +535678.81516572j,\n",
       "        -1054640.05758519 -569737.23711162j,\n",
       "          231193.6689445  -556057.84867697j, ...,\n",
       "         -259243.74528792 -240981.62450347j,\n",
       "          312357.18971136 +357967.95331175j,\n",
       "         -106013.48291918-1291984.43331787j]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = np.fft.fft2(image)\n",
    "dft "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   5.01466856+405.04647383j, -110.13795711-211.73443982j,\n",
       "        -117.47610428-152.29906894j, ..., -226.2578763 +102.68229933j,\n",
       "        -278.27478398-223.65054316j,  458.71028428-181.28776069j],\n",
       "       [  50.75231262-243.10538379j, -289.77078909 +89.31855703j,\n",
       "         191.72226313-424.68438958j, ...,  -89.29099051+431.01807999j,\n",
       "         -36.68020376 -86.22146172j,  118.3519698  -98.64615146j],\n",
       "       [  94.55687109+199.12249152j,  246.19854402-249.6011261j ,\n",
       "         130.60578091+341.56395339j, ...,  -36.49230304-217.04019669j,\n",
       "          64.98115685+152.5529037j ,   95.20409218-143.21785803j],\n",
       "       ...,\n",
       "       [  94.55687109-199.12249152j,   95.20409218+143.21785803j,\n",
       "          64.98115685-152.5529037j , ...,  136.51932035+124.94986145j,\n",
       "         130.60578091-341.56395339j,  246.19854402+249.6011261j ],\n",
       "       [  50.75231262+243.10538379j,  118.3519698  +98.64615146j,\n",
       "         -36.68020376 +86.22146172j, ...,  -40.52676182-658.81086512j,\n",
       "         191.72226313+424.68438958j, -289.77078909 -89.31855703j],\n",
       "       [   5.01466856-405.04647383j,  458.71028428+181.28776069j,\n",
       "        -278.27478398+223.65054316j, ...,   -8.57012433+452.90465932j,\n",
       "        -117.47610428+152.29906894j, -110.13795711+211.73443982j]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft_shifted = np.fft.fftshift(dft)  # Shift zero frequency to center\n",
    "dft_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = dft_shifted.shape\n",
    "center = (rows // 2, cols // 2)\n",
    "mask = np.zeros((rows, cols), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343, 474)\n"
     ]
    }
   ],
   "source": [
    "print((mask*dft_shifted).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19770384.              +0.j           788374.43465155-1184768.21422914j\n",
      "   -247797.26828835 +700144.43737151j ...\n",
      "   -341156.79129608 +833917.75854973j  -247797.26828835 -700144.43737151j\n",
      "    788374.43465155+1184768.21422914j]\n",
      " [ 1021914.81553875 -535678.81516572j  -106013.48291918+1291984.43331787j\n",
      "    312357.18971136 -357967.95331175j ...\n",
      "     94875.52718759 -691581.59465561j   231193.6689445  +556057.84867697j\n",
      "  -1054640.05758519 +569737.23711162j]\n",
      " [ -746130.83297157 -266878.13827965j  -196412.41213424 +534397.95836987j\n",
      "     87515.44773742 -346901.9140205j  ...\n",
      "     71700.69789589  +80922.05025297j   -33924.01450934 -929607.20436937j\n",
      "     31559.81479789 +423509.04880684j]\n",
      " ...\n",
      " [ -186573.474518   +418734.64761095j   120496.73123925 +610930.32937845j\n",
      "    264097.54402355 -549045.10505395j ...\n",
      "   -238859.2354294  +147466.42322418j  -466485.87127828 -199059.03770011j\n",
      "    363901.17548277 +139622.57484622j]\n",
      " [ -746130.83297157 +266878.13827965j    31559.81479789 -423509.04880684j\n",
      "    -33924.01450934 +929607.20436937j ...\n",
      "   -131863.56129784 -498345.61188647j    87515.44773742 +346901.9140205j\n",
      "   -196412.41213424 -534397.95836987j]\n",
      " [ 1021914.81553875 +535678.81516572j -1054640.05758519 -569737.23711162j\n",
      "    231193.6689445  -556057.84867697j ...\n",
      "   -259243.74528792 -240981.62450347j   312357.18971136 +357967.95331175j\n",
      "   -106013.48291918-1291984.43331787j]]\n"
     ]
    }
   ],
   "source": [
    "D0 = 100\n",
    "for u in range(rows):\n",
    "        for v in range(cols):\n",
    "            D = np.sqrt((u - center[0]) ** 2 + (v - center[1]) ** 2)\n",
    "            if D <= D0:\n",
    "                mask[u, v] = 1  # Retain low frequencies\n",
    "    \n",
    "filtered_dft = dft_shifted*mask\n",
    "\n",
    "print(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Step 4: Convert Back to Spatial Domain\n",
    "inverse_dft = np.fft.ifftshift(filtered_dft)\n",
    "image_filtered = np.fft.ifft2(inverse_dft)\n",
    "image_filtered = np.abs(image_filtered)\n",
    "image_filtered = np.clip(image_filtered, 0, 255).astype(np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Low-Pass Filtered Image\", image_filtered)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ideal_filter(dft_shifted, cutoff=10, type=\"low_pass\"):\n",
    "    rows, cols = dft_shifted.shape\n",
    "    center = (rows // 2, cols // 2)\n",
    "    \n",
    "    # Create a grid of distances from the center\n",
    "    x = np.arange(cols) - center[1]\n",
    "    y = np.arange(rows) - center[0]\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    distance = np.sqrt(xx**2 + yy**2)\n",
    "    \n",
    "    # Create the mask based on the filter type\n",
    "    if type == \"low_pass\" or \"lp\":  # Low-pass filter\n",
    "        mask = (distance <= cutoff).astype(np.uint8)\n",
    "    elif type == \"high_pass\" or \"hp\":  # High-pass filter\n",
    "        mask = (distance > cutoff).astype(np.uint8)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid filter type. Use 'lp' or 'hp'.\")\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def calculate_dft(img):\n",
    "    dft = np.fft.fft2(img)\n",
    "    dft_shifted = np.fft.fftshift(dft)\n",
    "    return dft_shifted, np.abs(dft_shifted)\n",
    "\n",
    "def filter_image(dft_shifted, mask):\n",
    "    filtered_dft = dft_shifted * mask\n",
    "    inverse_dft = np.fft.ifftshift(filtered_dft)\n",
    "    image_filtered = np.fft.ifft2(inverse_dft)\n",
    "    image_filtered = np.abs(image_filtered)\n",
    "    image_filtered = np.clip(image_filtered, 0, 255).astype(np.uint8)\n",
    "    return image_filtered\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_filter(img1, img2, cutoff1 = 10, cutoff2 = 10, type1 = \"lp\", type2 = \"lp\"):\n",
    "    \n",
    "    image1 = ideal_filter(img1, cutoff1, type1)\n",
    "    image2 = ideal_filter(img2, cutoff2, type2)\n",
    "    \n",
    "    if image1.shape != image2.shape:\n",
    "        # Assuming image1 is (320, 320) and image2 is (600, 600)\n",
    "        image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "        print(f\"image 1 shape {image1.shape}\")\n",
    "        print(f\"image 2 shape {image2.shape}\")\n",
    "        \n",
    "    hybird_image = image1 + image2\n",
    "    \n",
    "    return np.clip(hybird_image, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ideal_filter(dft_shifted, cutoff=10, type=\"low_pass\"):\n",
    "    rows, cols = dft_shifted.shape\n",
    "    center = (rows // 2, cols // 2)\n",
    "    \n",
    "    # Create a grid of distances from the center\n",
    "    x = np.arange(cols) - center[1]\n",
    "    y = np.arange(rows) - center[0]\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    distance = np.sqrt(xx**2 + yy**2)\n",
    "    \n",
    "    # Create the mask based on the filter type\n",
    "    if type == \"low_pass\" or type == \"lp\":  # Low-pass filter\n",
    "        mask = (distance <= cutoff).astype(np.uint8)\n",
    "    elif type == \"high_pass\" or type == \"hp\":  # High-pass filter\n",
    "        mask = (distance > cutoff).astype(np.uint8)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid filter type. Use 'lp' or 'hp'.\")\n",
    "    \n",
    "    return mask\n",
    "def convert_to_grayscale(image):\n",
    "    \"\"\"\n",
    "    Converts a BGR image to grayscale using the weighted sum method.\n",
    "\n",
    "    :param image: Input color image (BGR format).\n",
    "    :return: Grayscale image as NumPy array.\n",
    "    \"\"\"\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    r, g, b = image_rgb[:, :, 0], image_rgb[:, :, 1], image_rgb[:, :, 2]\n",
    "    \n",
    "    # Apply grayscale conversion formula\n",
    "    gray_image = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "    return gray_image.astype(np.uint8)\n",
    "\n",
    "def calculate_dft(img):\n",
    "    dft = np.fft.fft2(img)\n",
    "    dft_shifted = np.fft.fftshift(dft)\n",
    "    return dft_shifted, np.abs(dft_shifted)\n",
    "\n",
    "def filter_image(dft_shifted, mask):\n",
    "    filtered_dft = dft_shifted * mask\n",
    "    inverse_dft = np.fft.ifftshift(filtered_dft)\n",
    "    image_filtered = np.fft.ifft2(inverse_dft)\n",
    "    image_filtered = np.abs(image_filtered)\n",
    "    image_filtered = np.clip(image_filtered, 0, 255).astype(np.uint8)\n",
    "    return image_filtered\n",
    "\n",
    "def hybrid_filter(img1, img2, cutoff1=10, cutoff2=10, type1=\"lp\", type2=\"hp\"):\n",
    "    # Calculate DFT for both images\n",
    "    dft_shifted1, _ = calculate_dft(img1)\n",
    "    dft_shifted2, _ = calculate_dft(img2)\n",
    "    \n",
    "    # Create masks\n",
    "    mask1 = ideal_filter(dft_shifted1, cutoff1, type1)\n",
    "    mask2 = ideal_filter(dft_shifted2, cutoff2, type2)\n",
    "    \n",
    "    # Filter images\n",
    "    filtered_img1 = filter_image(dft_shifted1, mask1)\n",
    "    filtered_img2 = filter_image(dft_shifted2, mask2)\n",
    "    \n",
    "    # Resize images if necessary\n",
    "    if filtered_img1.shape != filtered_img2.shape:\n",
    "        filtered_img1 = cv2.resize(filtered_img1, (filtered_img2.shape[1], filtered_img2.shape[0]))\n",
    "    \n",
    "    # Combine images\n",
    "    hybrid_image = filtered_img1 + filtered_img2\n",
    "    \n",
    "    return np.clip(hybrid_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Load images\n",
    "img1 = cv2.imread('..\\data\\lena.png')\n",
    "img2 = cv2.imread('..\\data\\cameraman.png')\n",
    "img1_gray = convert_to_grayscale(img1)\n",
    "img2_gray = convert_to_grayscale(img2)   \n",
    "# Ensure images are loaded\n",
    "if img1 is None or img2 is None:\n",
    "    raise ValueError(\"One or both images could not be loaded. Please check the file paths.\")\n",
    "\n",
    "# Apply hybrid filter\n",
    "hybrid_image = hybrid_filter(img1, img2, cutoff1=30, cutoff2=30, type1=\"lp\", type2=\"hp\")\n",
    "\n",
    "# Display results\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Image 1')\n",
    "plt.imshow(img1, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Image 2')\n",
    "plt.imshow(img2, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Hybrid Image')\n",
    "plt.imshow(hybrid_image, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Image not found. Please check the file path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Check if the image was loaded successfully\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage not found. Please check the file path.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Calculate the DFT of the image\u001b[39;00m\n\u001b[0;32m     46\u001b[0m dft_shifted, magnitude_spectrum \u001b[38;5;241m=\u001b[39m calculate_dft(image)\n",
      "\u001b[1;31mValueError\u001b[0m: Image not found. Please check the file path."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ideal_filter(dft_shifted, cutoff=10, type=\"low_pass\"):\n",
    "    rows, cols = dft_shifted.shape\n",
    "    center = (rows // 2, cols // 2)\n",
    "    \n",
    "    # Create a grid of distances from the center\n",
    "    x = np.arange(cols) - center[1]\n",
    "    y = np.arange(rows) - center[0]\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    distance = np.sqrt(xx**2 + yy**2)\n",
    "    \n",
    "    # Create the mask based on the filter type\n",
    "    if type == \"low_pass\" or type == \"lp\":  # Low-pass filter\n",
    "        mask = (distance <= cutoff).astype(np.uint8)\n",
    "    elif type == \"high_pass\" or type == \"hp\":  # High-pass filter\n",
    "        mask = (distance > cutoff).astype(np.uint8)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid filter type. Use 'lp' or 'hp'.\")\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def calculate_dft(img):\n",
    "    dft = np.fft.fft2(img)\n",
    "    dft_shifted = np.fft.fftshift(dft)\n",
    "    return dft_shifted, np.abs(dft_shifted)\n",
    "\n",
    "def filter_image(dft_shifted, mask):\n",
    "    filtered_dft = dft_shifted * mask\n",
    "    inverse_dft = np.fft.ifftshift(filtered_dft)\n",
    "    image_filtered = np.fft.ifft2(inverse_dft)\n",
    "    image_filtered = np.abs(image_filtered)\n",
    "    image_filtered = np.clip(image_filtered, 0, 255).astype(np.uint8)\n",
    "    return image_filtered\n",
    "\n",
    "# Load an image in grayscale\n",
    "image = cv2.imread('input_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if the image was loaded successfully\n",
    "if image is None:\n",
    "    raise ValueError(\"Image not found. Please check the file path.\")\n",
    "\n",
    "# Calculate the DFT of the image\n",
    "dft_shifted, magnitude_spectrum = calculate_dft(image)\n",
    "\n",
    "# Create a low-pass filter mask\n",
    "low_pass_mask = ideal_filter(dft_shifted, cutoff=30, type=\"lp\")\n",
    "\n",
    "# Apply the low-pass filter\n",
    "low_pass_filtered_image = filter_image(dft_shifted, low_pass_mask)\n",
    "\n",
    "# Create a high-pass filter mask\n",
    "high_pass_mask = ideal_filter(dft_shifted, cutoff=30, type=\"hp\")\n",
    "\n",
    "# Apply the high-pass filter\n",
    "high_pass_filtered_image = filter_image(dft_shifted, high_pass_mask)\n",
    "\n",
    "# Display the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Original Image\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "# Magnitude Spectrum\n",
    "plt.subplot(2, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
